import os
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_core.documents import Document
from .legal_search import get_law_content_xml, parse_articles_from_xml, search_law_id
from dotenv import load_dotenv

load_dotenv()

# ë¡œì»¬ DB ì €ì¥ ê²½ë¡œ ë° ëŒ€ìƒ ë²•ë ¹ ì •ì˜
DB_PATH = "../data/faiss_law_db" 
TARGET_LAWS = [
    # 1. ê·¼ë¡œê´€ê³„ì˜ ê¸°ë³¸
    "ê·¼ë¡œê¸°ì¤€ë²•",
    "ìµœì €ì„ê¸ˆë²•",
    "ê·¼ë¡œìí‡´ì§ê¸‰ì—¬ ë³´ì¥ë²•",
    "ê¸°ê°„ì œ ë° ë‹¨ì‹œê°„ê·¼ë¡œì ë³´í˜¸ ë“±ì— ê´€í•œ ë²•ë¥ ",
    "íŒŒê²¬ê·¼ë¡œì ë³´í˜¸ ë“±ì— ê´€í•œ ë²•ë¥ ",

    # 2. ê¸‰ì—¬, ë³´í—˜ ë° ë³µì§€ ê´€ë ¨
    "ì„ê¸ˆì±„ê¶Œë³´ì¥ë²•",
    "ê³ ìš©ë³´í—˜ë²•",
    "ì‚°ì—…ì¬í•´ë³´ìƒë³´í—˜ë²•",
    "êµ­ë¯¼ê±´ê°•ë³´í—˜ë²•",
    "êµ­ë¯¼ì—°ê¸ˆë²•",
    "ê·¼ë¡œë³µì§€ê¸°ë³¸ë²•",

    # 3. ì°¨ë³„ ê¸ˆì§€ ë° ì¸ê¶Œ ë³´í˜¸
    "ë‚¨ë…€ê³ ìš©í‰ë“±ê³¼ ì¼ã†ê°€ì • ì–‘ë¦½ ì§€ì›ì— ê´€í•œ ë²•ë¥ ",
    "ê³ ìš©ìƒ ì—°ë ¹ì°¨ë³„ê¸ˆì§€ ë° ê³ ë ¹ìê³ ìš©ì´‰ì§„ì— ê´€í•œ ë²•ë¥ ",
    "ì¥ì• ì¸ê³ ìš©ì´‰ì§„ ë° ì§ì—…ì¬í™œë²•",
    "ì±„ìš©ì ˆì°¨ì˜ ê³µì •í™”ì— ê´€í•œ ë²•ë¥ ",

    # 4. ì•ˆì „ ë° ê°œì¸ì •ë³´
    "ì‚°ì—…ì•ˆì „ë³´ê±´ë²•",
    "ì¤‘ëŒ€ì¬í•´ ì²˜ë²Œ ë“±ì— ê´€í•œ ë²•ë¥ ",
    "ê°œì¸ì •ë³´ ë³´í˜¸ë²•",
    "ìœ„ì¹˜ì •ë³´ì˜ ë³´í˜¸ ë° ì´ìš© ë“±ì— ê´€í•œ ë²•ë¥ ",

    # 5. ì§€ì‹ì¬ì‚°ê¶Œ ë° ë¹„ë°€ìœ ì§€
    "ë¶€ì •ê²½ìŸë°©ì§€ ë° ì˜ì—…ë¹„ë°€ë³´í˜¸ì— ê´€í•œ ë²•ë¥ ",
    "ë°œëª…ì§„í¥ë²•",
    "ì €ì‘ê¶Œë²•",

    # 6. ì¼ë°˜ ë²• ì›ì¹™ ë° ë³´ì¦
    "ì‹ ì›ë³´ì¦ë²•",
    "ì•½ê´€ì˜ ê·œì œì— ê´€í•œ ë²•ë¥ "
]

class LawContextManager:
    def __init__(self):
        self.vectorstore = None
        # ê·¼ë¡œê³„ì•½ì„œ ë¶„ì„ì— í•„ìˆ˜ì ì¸ '3ëŒ€ì¥ ë²•ë ¹'ì„ ë¯¸ë¦¬ ì •ì˜
        self.target_laws = TARGET_LAWS
        # ì„ë² ë”© ëª¨ë¸ì€ í•œ ë²ˆë§Œ ë¡œë“œ
        self.embeddings = HuggingFaceEmbeddings(model_name="jhgan/ko-sbert-nli")

    def initialize_database(self):
        """
        ë¡œì»¬ DB ê²½ë¡œ (DB_PATH)ë¥¼ í™•ì¸í•˜ì—¬ DBë¥¼ ë¡œë“œí•˜ê±°ë‚˜ ìƒˆë¡œ êµ¬ì¶• í›„ ì €ì¥í•©ë‹ˆë‹¤.
        """
        if self.vectorstore is not None:
            print("ğŸ’¡ ë²•ë ¹ DBê°€ ì´ë¯¸ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return

        # 1. ë¡œì»¬ DB íŒŒì¼ ì¡´ì¬ í™•ì¸ ë° ë¡œë“œ
        if os.path.exists(DB_PATH) and os.path.isdir(DB_PATH):
            print(f"âœ… [ì´ˆê¸°í™”] ê¸°ì¡´ ë²•ë ¹ DB ë¡œë“œ ì¤‘... (ê²½ë¡œ: {DB_PATH})")
            try:
                # ë¡œì»¬ DB ë¡œë“œ (allow_dangerous_deserialization=True ì„¤ì •)
                self.vectorstore = FAISS.load_local(DB_PATH, self.embeddings, allow_dangerous_deserialization=True)
                print("âœ… [ì´ˆê¸°í™”] ë²•ë ¹ DB ë¡œë“œ ì™„ë£Œ!")
                return
            except Exception as e:
                print(f"âš ï¸ ê¸°ì¡´ DB ë¡œë“œ ì‹¤íŒ¨: {e}. DBë¥¼ ìƒˆë¡œ êµ¬ì¶•í•©ë‹ˆë‹¤.")
        
        # 2. ì‹ ê·œ DB êµ¬ì¶• (ë¡œì»¬ì— DBê°€ ì—†ê±°ë‚˜ ë¡œë“œ ì‹¤íŒ¨ ì‹œ)
        print("ğŸ“š [ì´ˆê¸°í™”] í•„ìˆ˜ ë²•ë ¹ ë°ì´í„° ì‹ ê·œ êµ¬ì¶•ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        all_docs = []

        for law_name in self.target_laws:
            print(f"  ğŸ” '{law_name}' ê²€ìƒ‰ ì¤‘...")
            
            # 2-1. ë²•ë ¹ ID ì°¾ê¸°
            law_id, real_name = search_law_id(law_name)
            if not law_id: continue
            
            print(f"  ğŸ“¥ '{real_name}'(ID:{law_id}) ë³¸ë¬¸ ë‹¤ìš´ë¡œë“œ ë° íŒŒì‹±...")
            
            # 2-2. ì „ë¬¸ ê°€ì ¸ì˜¤ê¸° ë° ì¡°í•­ íŒŒì‹±
            xml_content = get_law_content_xml(law_id)
            articles = parse_articles_from_xml(xml_content)
            
            # 2-3. ë¬¸ì„œ ê°ì²´ë¡œ ë³€í™˜
            current_docs = []
            for article in articles:
                # ë©”íƒ€ë°ì´í„°ë¥¼ 'source'ë§Œ ì¶”ê°€ (ê¸°ì¡´ êµ¬ì¡° ìœ ì§€)
                doc = Document(
                    page_content=article,
                    metadata={"source": real_name}
                )
                current_docs.append(doc)
            all_docs.extend(current_docs)
            print(f"    ğŸ‘‰ {len(current_docs)}ê°œ ì¡°í•­ ì¶”ì¶œ ì™„ë£Œ")
        
        if not all_docs:
            print("âŒ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ì–´ DB ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return

        # 3. ë²¡í„° DB ìƒì„± ë° ë¡œì»¬ ì €ì¥
        print(f"âš¡ ì´ {len(all_docs)}ê°œ ì¡°í•­ ë²¡í„°í™” ë° DB ì €ì¥ ì‹œì‘...")
        self.vectorstore = FAISS.from_documents(all_docs, self.embeddings)
        
        # ë¡œì»¬ ì €ì¥
        os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)
        self.vectorstore.save_local(DB_PATH)
        
        print(f"âœ… ë²•ë ¹ DB ì‹ ê·œ êµ¬ì¶• ë° ì €ì¥ ì™„ë£Œ! (ì´ {len(all_docs)}ê°œ ì¡°í•­, ê²½ë¡œ: {os.path.abspath(DB_PATH)})")


    def search_relevant_laws(self, query, k=2):
        """
        ë¡œì»¬ì— ë¡œë“œëœ DBì—ì„œ ê´€ë ¨ ì¡°í•­ì„ ì¦‰ì‹œ ì°¾ìŠµë‹ˆë‹¤. (DBê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìœ¼ë©´ ë¡œë“œ ì‹œë„)
        """
        # DBê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìœ¼ë©´ ë¡œë“œ ì‹œë„
        if not self.vectorstore:
            self.initialize_database()
        
        if not self.vectorstore:
            print("âš ï¸ ë²•ë ¹ DBê°€ ì¡´ì¬í•˜ì§€ ì•Šì•„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        print(f"ğŸ” DBì—ì„œ '{query[:20]}...' ê´€ë ¨ ë²•ë ¹ {k}ê°œ ê²€ìƒ‰ ì¤‘...")
        # ìœ ì‚¬ë„ ê²€ìƒ‰
        docs = self.vectorstore.similarity_search(query, k=k)
        # ì¡°í•­ ë‚´ìš©ë§Œ ë°˜í™˜
        return [doc.page_content for doc in docs]